{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLR_Lobith.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPxgiTOHcG1mpqwen7lsRM6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Maryam-Afshari/thesis/blob/master/MLR_Lobith.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# checking out the GPU\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RIChmcHDWrX",
        "outputId": "9a835d19-681c-4dc3-cd11-094674418a25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Jun 18 19:19:40 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   47C    P0    29W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# checking out the memory\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_2vRXpdDVrg",
        "outputId": "4940c0d6-3bec-455b-ea93-9f0684971853"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 27.3 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Running MLR on Lobith station "
      ],
      "metadata": {
        "id": "HLQnWYWODdRx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install hydroeval"
      ],
      "metadata": {
        "id": "j9SGN0thDKyc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import hydroeval as he\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "zC9CgAOvDLHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46USf4nxDLNh",
        "outputId": "eccd90ac-2095-4ee5-ebb3-3a62d7a1e670"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reading data\n",
        "lobith = pd.read_csv('/content/drive/MyDrive/Thesis-Afshari/data/lobith.csv',index_col=0)\n",
        "q_lobith = pd.read_csv(\"/content/drive/MyDrive/Thesis-Afshari/data/q_lobith.csv\",index_col=0)\n"
      ],
      "metadata": {
        "id": "-YrGibLyDLQ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature engineering"
      ],
      "metadata": {
        "id": "mGD68aGREAky"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# making lagged variables\n",
        "\n",
        "# define the number of lags\n",
        "TIME_STEPS = 55\n",
        "\n",
        "#add the lagged variables for predictors to the dataframe\n",
        "for i, var in enumerate(lobith[[\"et\",\"p\",\"t\"]]):\n",
        "  for step in range(0, TIME_STEPS - 1):\n",
        "    lobith.insert(i*(TIME_STEPS) + 1,\n",
        "                 f'{var}_lag_{TIME_STEPS - 1 - step}',\n",
        "                 lobith[var].shift(TIME_STEPS - 1 - step))\n",
        "\n",
        "#remove the first TIME_STEPS - 1 rows since they will contain NA values\n",
        "lobith = lobith.iloc[TIME_STEPS - 1:,:].reset_index(drop=True)\n",
        "q_lobith = q_lobith.iloc[TIME_STEPS - 1:,:].reset_index(drop=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQ62CpmLDLYb",
        "outputId": "f9c187dc-fc55-4b5a-8927-b82af0d06d4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2822: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  if self.run_code(code, result):\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train-test split and defineing variables\n"
      ],
      "metadata": {
        "id": "RWpJFzzREJrj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train-test split\n",
        "len_ = int(0.75 * lobith.shape[0])\n",
        "\n",
        "df_train = lobith[:len_]\n",
        "df_test = lobith[len_:]\n",
        "\n",
        "# x-train without lagged vars\n",
        "X_train = df_train[[\"et\",\"t\",\"p\"]]\n",
        "\n",
        "# x-train with lagged vars\n",
        "X_train_lagged = df_train.drop(columns = [\"obs\",\"datetime\"], axis =1)\n",
        "y_train = df_train.obs\n",
        "\n",
        "# x-test without lagged vars\n",
        "X_test = df_test[[\"et\",\"t\",\"p\"]]\n",
        "\n",
        "# x-test with lagged vars\n",
        "X_test_lagged = df_test.drop(columns = [\"obs\",\"datetime\"], axis =1)\n",
        "y_test = df_test.obs"
      ],
      "metadata": {
        "id": "KnWmAbs5EIUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Normalising data"
      ],
      "metadata": {
        "id": "mF-JlJzzESTm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# normalising perdictors \n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# normalising perdictors for model with the lagged varibales\n",
        "scaler_lagged = MinMaxScaler()\n",
        "X_train_lagged = scaler_lagged.fit_transform(X_train_lagged)\n",
        "X_test_lagged = scaler_lagged.transform(X_test_lagged)"
      ],
      "metadata": {
        "id": "tCJ5MGViEIbd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model"
      ],
      "metadata": {
        "id": "YGcNO2CUEubZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating an object of LinearRegression class\n",
        "lm = LinearRegression()\n",
        "\n",
        "# fitting the training data\n",
        "lm.fit(X_train,y_train)\n",
        "\n",
        "# evaluating the model\n",
        "lm.score(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWVZa4G_E0xG",
        "outputId": "eaeef43a-304c-4c44-b28b-b58365144782"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.036785669681463795"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating an object of LinearRegression class\n",
        "lm_lag = LinearRegression()\n",
        "\n",
        "# fitting the training data for model with the lagged variables\n",
        "lm_lag.fit(X_train_lagged,y_train)\n",
        "\n",
        "# evaluating the model\n",
        "lm_lag.score(X_test_lagged, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdqdD_7NE2IO",
        "outputId": "aeca80a1-fb92-4c79-8071-7376b1db897c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6723610120045485"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation"
      ],
      "metadata": {
        "id": "whndiHOSNHfU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate pcr model using nse and kge\n",
        "streamflow_pcr = q_lobith.pcr[len_:]\n",
        "nse_pcr = he.evaluator(he.nse, streamflow_pcr,y_test)\n",
        "kge_pcr, r_pcr, alpha_pcr, beta_pcr = he.evaluator(he.kge, streamflow_pcr, y_test)\n",
        "print(\"The nse and kge of the PCR model are {:.2} and {:.2} respectively.\".format(nse_pcr[0], kge_pcr[0]))\n",
        "\n",
        "# predicting for model with only meteorological variables\n",
        "y_pred =  lm.predict(X_test)\n",
        "\n",
        "# predicting for model with meteorological variables + lagged variables\n",
        "y_pred_lagged = lm_lag.predict(X_test_lagged)\n",
        "\n",
        "# evaluate the prediction using nse and kge for model with only meteorological variables\n",
        "nse = he.evaluator(he.nse, y_pred, y_test)\n",
        "kge, r, alpha, beta = he.evaluator(he.kge, y_pred, y_test)\n",
        "\n",
        "# evaluate the prediction using nse and kge for model with meteorological variables + lagged variables\n",
        "nse_lag = he.evaluator(he.nse, y_pred_lagged, y_test)\n",
        "kge_lag, r_lag, alpha_lag, beta_lag = he.evaluator(he.kge, y_pred_lagged, y_test)\n",
        "print(\"The nse and kge of the linear model are {:.2} and {:.2} respectively.\".format(nse[0], kge[0]))\n",
        "print(\"The nse and kge of the linear model including lagged variables are {:.2} and {:.2} respectively.\".format(nse_lag[0], kge_lag[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FyhL2aVQE8D6",
        "outputId": "2fd2ade1-871c-42fd-9112-7bb79952279f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The nse and kge of the PCR model are 0.36 and 0.55 respectively.\n",
            "The nse and kge of the linear model are 0.037 and -0.047 respectively.\n",
            "The nse and kge of the linear model including lagged variables are 0.67 and 0.76 respectively.\n"
          ]
        }
      ]
    }
  ]
}