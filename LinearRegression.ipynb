{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "pred_basel = pd.read_csv(\"data/basel.csv\",index_col=0)\n",
    "pred_basel = pred_basel.set_index(\"datetime\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "                 obs         pcr        res\ndatetime                                   \n1981-01-01   670.000   605.06915   64.93085\n1981-01-02   647.000   599.35767   47.64233\n1981-01-03   727.000   874.38354 -147.38354\n1981-01-04  1363.000   998.86804  364.13196\n1981-01-05  1202.000   968.06270  233.93730\n...              ...         ...        ...\n2000-12-27   662.035  1055.62610 -393.59110\n2000-12-28   656.253  1027.90730 -371.65430\n2000-12-29   652.150   860.76306 -208.61306\n2000-12-30   641.549   655.83777  -14.28877\n2000-12-31   599.663   620.78060  -21.11760\n\n[7305 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>obs</th>\n      <th>pcr</th>\n      <th>res</th>\n    </tr>\n    <tr>\n      <th>datetime</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1981-01-01</th>\n      <td>670.000</td>\n      <td>605.06915</td>\n      <td>64.93085</td>\n    </tr>\n    <tr>\n      <th>1981-01-02</th>\n      <td>647.000</td>\n      <td>599.35767</td>\n      <td>47.64233</td>\n    </tr>\n    <tr>\n      <th>1981-01-03</th>\n      <td>727.000</td>\n      <td>874.38354</td>\n      <td>-147.38354</td>\n    </tr>\n    <tr>\n      <th>1981-01-04</th>\n      <td>1363.000</td>\n      <td>998.86804</td>\n      <td>364.13196</td>\n    </tr>\n    <tr>\n      <th>1981-01-05</th>\n      <td>1202.000</td>\n      <td>968.06270</td>\n      <td>233.93730</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2000-12-27</th>\n      <td>662.035</td>\n      <td>1055.62610</td>\n      <td>-393.59110</td>\n    </tr>\n    <tr>\n      <th>2000-12-28</th>\n      <td>656.253</td>\n      <td>1027.90730</td>\n      <td>-371.65430</td>\n    </tr>\n    <tr>\n      <th>2000-12-29</th>\n      <td>652.150</td>\n      <td>860.76306</td>\n      <td>-208.61306</td>\n    </tr>\n    <tr>\n      <th>2000-12-30</th>\n      <td>641.549</td>\n      <td>655.83777</td>\n      <td>-14.28877</td>\n    </tr>\n    <tr>\n      <th>2000-12-31</th>\n      <td>599.663</td>\n      <td>620.78060</td>\n      <td>-21.11760</td>\n    </tr>\n  </tbody>\n</table>\n<p>7305 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_basel = pd.read_csv(\"data/q_basel.csv\",index_col=0)\n",
    "q_basel"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Feature Engineering"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wescap\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3361: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    }
   ],
   "source": [
    "# making 50 lagged variables\n",
    "TIME_STEPS = 50\n",
    "is_lag = TIME_STEPS > 1\n",
    "if is_lag:\n",
    "  #add the lagged variables to the dataframe\n",
    "  for i, var in enumerate(pred_basel[[\"et\",\"p\",\"t\"]]):\n",
    "    for step in range(0, TIME_STEPS - 1):\n",
    "      pred_basel.insert(i*(TIME_STEPS) + 1,\n",
    "                        f'{var}_lag_{TIME_STEPS - 1 - step}',\n",
    "                        pred_basel[var].shift(TIME_STEPS - 1 - step))\n",
    "\n",
    "# remove the first TIME_STEPS - 1 rows since they are now NA values\n",
    "pred_basel = pred_basel.iloc[TIME_STEPS - 1:,:].reset_index(drop=True)\n",
    "q_basel = q_basel.iloc[TIME_STEPS - 1:,:].reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train-test split"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "#define number of observations and the train split proportion\n",
    "# predictors and output var\n",
    "len_ = int(0.75 * pred_basel.shape[0])\n",
    "\n",
    "df_train = pred_basel[:len_]\n",
    "df_test = pred_basel[len_:]\n",
    "\n",
    "# x train without lagged vars\n",
    "X_train = df_train[[\"et\",\"t\",\"p\"]]\n",
    "\n",
    "# x train with lagged vars\n",
    "X_train_lagged = df_train.drop(\"obs\", axis =1)\n",
    "y_train = df_train.obs\n",
    "\n",
    "# x test without lagged vars\n",
    "X_test = df_test[[\"et\",\"t\",\"p\"]]\n",
    "\n",
    "# x test with lagged vars\n",
    "X_test_lagged = df_test.drop(\"obs\", axis =1)\n",
    "y_test = df_test.obs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "            et  et_lag_1  et_lag_2  et_lag_3  et_lag_4  et_lag_5  et_lag_6  \\\n0     0.000532  0.000553  0.000571  0.000580  0.000543  0.000507  0.000452   \n1     0.000547  0.000532  0.000553  0.000571  0.000580  0.000543  0.000507   \n2     0.000569  0.000547  0.000532  0.000553  0.000571  0.000580  0.000543   \n3     0.000593  0.000569  0.000547  0.000532  0.000553  0.000571  0.000580   \n4     0.000644  0.000593  0.000569  0.000547  0.000532  0.000553  0.000571   \n...        ...       ...       ...       ...       ...       ...       ...   \n5437  0.000813  0.000705  0.000777  0.000723  0.000530  0.000416  0.000591   \n5438  0.000827  0.000813  0.000705  0.000777  0.000723  0.000530  0.000416   \n5439  0.000885  0.000827  0.000813  0.000705  0.000777  0.000723  0.000530   \n5440  0.000861  0.000885  0.000827  0.000813  0.000705  0.000777  0.000723   \n5441  0.000770  0.000861  0.000885  0.000827  0.000813  0.000705  0.000777   \n\n      et_lag_7  et_lag_8  et_lag_9  ...  t_lag_40  t_lag_41   t_lag_42  \\\n0     0.000483  0.000623  0.000770  ... -5.646553 -8.999503 -10.731832   \n1     0.000452  0.000483  0.000623  ... -5.925995 -5.646553  -8.999503   \n2     0.000507  0.000452  0.000483  ... -5.499934 -5.925995  -5.646553   \n3     0.000543  0.000507  0.000452  ... -4.769065 -5.499934  -5.925995   \n4     0.000580  0.000543  0.000507  ... -2.298974 -4.769065  -5.499934   \n...        ...       ...       ...  ...       ...       ...        ...   \n5437  0.000626  0.000697  0.000568  ... -0.870762  0.681613   2.573417   \n5438  0.000591  0.000626  0.000697  ... -0.964901 -0.870762   0.681613   \n5439  0.000416  0.000591  0.000626  ...  2.404177 -0.964901  -0.870762   \n5440  0.000530  0.000416  0.000591  ...  2.084055  2.404177  -0.964901   \n5441  0.000723  0.000530  0.000416  ... -2.153785  2.084055   2.404177   \n\n       t_lag_43   t_lag_44   t_lag_45   t_lag_46  t_lag_47  t_lag_48  t_lag_49  \n0     -6.366458  -2.218504  -2.055391   1.019687  5.165919  2.172385 -0.250816  \n1    -10.731832  -6.366458  -2.218504  -2.055391  1.019687  5.165919  2.172385  \n2     -8.999503 -10.731832  -6.366458  -2.218504 -2.055391  1.019687  5.165919  \n3     -5.646553  -8.999503 -10.731832  -6.366458 -2.218504 -2.055391  1.019687  \n4     -5.925995  -5.646553  -8.999503 -10.731832 -6.366458 -2.218504 -2.055391  \n...         ...        ...        ...        ...       ...       ...       ...  \n5437   4.436017   3.448374   1.560776   2.177809  3.985582  2.886545 -2.100167  \n5438   2.573417   4.436017   3.448374   1.560776  2.177809  3.985582  2.886545  \n5439   0.681613   2.573417   4.436017   3.448374  1.560776  2.177809  3.985582  \n5440  -0.870762   0.681613   2.573417   4.436017  3.448374  1.560776  2.177809  \n5441  -0.964901  -0.870762   0.681613   2.573417  4.436017  3.448374  1.560776  \n\n[5442 rows x 150 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>et</th>\n      <th>et_lag_1</th>\n      <th>et_lag_2</th>\n      <th>et_lag_3</th>\n      <th>et_lag_4</th>\n      <th>et_lag_5</th>\n      <th>et_lag_6</th>\n      <th>et_lag_7</th>\n      <th>et_lag_8</th>\n      <th>et_lag_9</th>\n      <th>...</th>\n      <th>t_lag_40</th>\n      <th>t_lag_41</th>\n      <th>t_lag_42</th>\n      <th>t_lag_43</th>\n      <th>t_lag_44</th>\n      <th>t_lag_45</th>\n      <th>t_lag_46</th>\n      <th>t_lag_47</th>\n      <th>t_lag_48</th>\n      <th>t_lag_49</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.000532</td>\n      <td>0.000553</td>\n      <td>0.000571</td>\n      <td>0.000580</td>\n      <td>0.000543</td>\n      <td>0.000507</td>\n      <td>0.000452</td>\n      <td>0.000483</td>\n      <td>0.000623</td>\n      <td>0.000770</td>\n      <td>...</td>\n      <td>-5.646553</td>\n      <td>-8.999503</td>\n      <td>-10.731832</td>\n      <td>-6.366458</td>\n      <td>-2.218504</td>\n      <td>-2.055391</td>\n      <td>1.019687</td>\n      <td>5.165919</td>\n      <td>2.172385</td>\n      <td>-0.250816</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.000547</td>\n      <td>0.000532</td>\n      <td>0.000553</td>\n      <td>0.000571</td>\n      <td>0.000580</td>\n      <td>0.000543</td>\n      <td>0.000507</td>\n      <td>0.000452</td>\n      <td>0.000483</td>\n      <td>0.000623</td>\n      <td>...</td>\n      <td>-5.925995</td>\n      <td>-5.646553</td>\n      <td>-8.999503</td>\n      <td>-10.731832</td>\n      <td>-6.366458</td>\n      <td>-2.218504</td>\n      <td>-2.055391</td>\n      <td>1.019687</td>\n      <td>5.165919</td>\n      <td>2.172385</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.000569</td>\n      <td>0.000547</td>\n      <td>0.000532</td>\n      <td>0.000553</td>\n      <td>0.000571</td>\n      <td>0.000580</td>\n      <td>0.000543</td>\n      <td>0.000507</td>\n      <td>0.000452</td>\n      <td>0.000483</td>\n      <td>...</td>\n      <td>-5.499934</td>\n      <td>-5.925995</td>\n      <td>-5.646553</td>\n      <td>-8.999503</td>\n      <td>-10.731832</td>\n      <td>-6.366458</td>\n      <td>-2.218504</td>\n      <td>-2.055391</td>\n      <td>1.019687</td>\n      <td>5.165919</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.000593</td>\n      <td>0.000569</td>\n      <td>0.000547</td>\n      <td>0.000532</td>\n      <td>0.000553</td>\n      <td>0.000571</td>\n      <td>0.000580</td>\n      <td>0.000543</td>\n      <td>0.000507</td>\n      <td>0.000452</td>\n      <td>...</td>\n      <td>-4.769065</td>\n      <td>-5.499934</td>\n      <td>-5.925995</td>\n      <td>-5.646553</td>\n      <td>-8.999503</td>\n      <td>-10.731832</td>\n      <td>-6.366458</td>\n      <td>-2.218504</td>\n      <td>-2.055391</td>\n      <td>1.019687</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.000644</td>\n      <td>0.000593</td>\n      <td>0.000569</td>\n      <td>0.000547</td>\n      <td>0.000532</td>\n      <td>0.000553</td>\n      <td>0.000571</td>\n      <td>0.000580</td>\n      <td>0.000543</td>\n      <td>0.000507</td>\n      <td>...</td>\n      <td>-2.298974</td>\n      <td>-4.769065</td>\n      <td>-5.499934</td>\n      <td>-5.925995</td>\n      <td>-5.646553</td>\n      <td>-8.999503</td>\n      <td>-10.731832</td>\n      <td>-6.366458</td>\n      <td>-2.218504</td>\n      <td>-2.055391</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5437</th>\n      <td>0.000813</td>\n      <td>0.000705</td>\n      <td>0.000777</td>\n      <td>0.000723</td>\n      <td>0.000530</td>\n      <td>0.000416</td>\n      <td>0.000591</td>\n      <td>0.000626</td>\n      <td>0.000697</td>\n      <td>0.000568</td>\n      <td>...</td>\n      <td>-0.870762</td>\n      <td>0.681613</td>\n      <td>2.573417</td>\n      <td>4.436017</td>\n      <td>3.448374</td>\n      <td>1.560776</td>\n      <td>2.177809</td>\n      <td>3.985582</td>\n      <td>2.886545</td>\n      <td>-2.100167</td>\n    </tr>\n    <tr>\n      <th>5438</th>\n      <td>0.000827</td>\n      <td>0.000813</td>\n      <td>0.000705</td>\n      <td>0.000777</td>\n      <td>0.000723</td>\n      <td>0.000530</td>\n      <td>0.000416</td>\n      <td>0.000591</td>\n      <td>0.000626</td>\n      <td>0.000697</td>\n      <td>...</td>\n      <td>-0.964901</td>\n      <td>-0.870762</td>\n      <td>0.681613</td>\n      <td>2.573417</td>\n      <td>4.436017</td>\n      <td>3.448374</td>\n      <td>1.560776</td>\n      <td>2.177809</td>\n      <td>3.985582</td>\n      <td>2.886545</td>\n    </tr>\n    <tr>\n      <th>5439</th>\n      <td>0.000885</td>\n      <td>0.000827</td>\n      <td>0.000813</td>\n      <td>0.000705</td>\n      <td>0.000777</td>\n      <td>0.000723</td>\n      <td>0.000530</td>\n      <td>0.000416</td>\n      <td>0.000591</td>\n      <td>0.000626</td>\n      <td>...</td>\n      <td>2.404177</td>\n      <td>-0.964901</td>\n      <td>-0.870762</td>\n      <td>0.681613</td>\n      <td>2.573417</td>\n      <td>4.436017</td>\n      <td>3.448374</td>\n      <td>1.560776</td>\n      <td>2.177809</td>\n      <td>3.985582</td>\n    </tr>\n    <tr>\n      <th>5440</th>\n      <td>0.000861</td>\n      <td>0.000885</td>\n      <td>0.000827</td>\n      <td>0.000813</td>\n      <td>0.000705</td>\n      <td>0.000777</td>\n      <td>0.000723</td>\n      <td>0.000530</td>\n      <td>0.000416</td>\n      <td>0.000591</td>\n      <td>...</td>\n      <td>2.084055</td>\n      <td>2.404177</td>\n      <td>-0.964901</td>\n      <td>-0.870762</td>\n      <td>0.681613</td>\n      <td>2.573417</td>\n      <td>4.436017</td>\n      <td>3.448374</td>\n      <td>1.560776</td>\n      <td>2.177809</td>\n    </tr>\n    <tr>\n      <th>5441</th>\n      <td>0.000770</td>\n      <td>0.000861</td>\n      <td>0.000885</td>\n      <td>0.000827</td>\n      <td>0.000813</td>\n      <td>0.000705</td>\n      <td>0.000777</td>\n      <td>0.000723</td>\n      <td>0.000530</td>\n      <td>0.000416</td>\n      <td>...</td>\n      <td>-2.153785</td>\n      <td>2.084055</td>\n      <td>2.404177</td>\n      <td>-0.964901</td>\n      <td>-0.870762</td>\n      <td>0.681613</td>\n      <td>2.573417</td>\n      <td>4.436017</td>\n      <td>3.448374</td>\n      <td>1.560776</td>\n    </tr>\n  </tbody>\n</table>\n<p>5442 rows × 150 columns</p>\n</div>"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_lagged"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Normalize the data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "# normalising for without lagged\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# normalising data with lagged\n",
    "scaler_lagged = MinMaxScaler()\n",
    "\n",
    "X_train_lagged = scaler_lagged.fit_transform(X_train_lagged)\n",
    "\n",
    "X_test_lagged = scaler_lagged.transform(X_test_lagged)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "0.12108233009697922"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating an object of LinearRegression class\n",
    "lm = LinearRegression()\n",
    "\n",
    "# fitting the training data\n",
    "lm.fit(X_train,y_train)\n",
    "\n",
    "#evaluate the model\n",
    "lm.score(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "0.6610153261270394"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating an object of LinearRegression class\n",
    "lm_lag = LinearRegression()\n",
    "\n",
    "# fitting the training data\n",
    "lm_lag.fit(X_train_lagged,y_train)\n",
    "\n",
    "#evaluate the model\n",
    "lm_lag.score(X_test_lagged, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The nse and kge of the PCR model are 0.22 and 0.64.\n",
      "The nse and kge of the linear model are 0.12 and 0.12.\n",
      "The nse and kge of the linear model with lag variables are 0.66 and 0.71.\n"
     ]
    }
   ],
   "source": [
    "streamflow_pcr = q_basel.pcr[len_:]\n",
    "\n",
    "# evaluate pcr model using nse and kge\n",
    "nse_pcr = he.evaluator(he.nse, streamflow_pcr,y_test)\n",
    "kge_pcr, r_pcr, alpha_pcr, beta_pcr = he.evaluator(he.kge, streamflow_pcr, y_test)\n",
    "print(\"The nse and kge of the PCR model are {:.2} and {:.2}.\".format(nse_pcr[0], kge_pcr[0]))\n",
    "\n",
    "# predicting for model with only meteorological variables\n",
    "y_pred =  lm.predict(X_test)\n",
    "\n",
    "# predicting for model with meteorological variables + lagged variables\n",
    "y_pred_lagged = lm_lag.predict(X_test_lagged)\n",
    "\n",
    "# evaluate the prediction using nse and kge for model with only meteorological variables\n",
    "nse = he.evaluator(he.nse, y_pred, y_test)\n",
    "kge, r, alpha, beta = he.evaluator(he.kge, y_pred, y_test)\n",
    "\n",
    "# evaluate the prediction using nse and kge for model with meteorological variables + lagged variables\n",
    "nse_lag = he.evaluator(he.nse, y_pred_lagged, y_test)\n",
    "kge_lag, r_lag, alpha_lag, beta_lag = he.evaluator(he.kge, y_pred_lagged, y_test)\n",
    "print(\"The nse and kge of the linear model are {:.2} and {:.2}.\".format(nse[0], kge[0]))\n",
    "print(\"The nse and kge of the linear model including lagged variables are {:.2} and {:.2}.\".format(nse_lag[0], kge_lag[0]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}