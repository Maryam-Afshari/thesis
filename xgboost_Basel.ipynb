{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "xgboost_Basel.ipynb",
      "provenance": [],
      "mount_file_id": "1cW2b-HR2sOCLLXNA5sI3Yql7IW_16zd1",
      "authorship_tag": "ABX9TyPUWiw6j7wzVaZv9EVSuCHH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Maryam-Afshari/thesis/blob/master/xgboost_Basel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# checking out the GPU\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEcZL5LXl3m8",
        "outputId": "2c2bde28-2497-4c4a-c561-85f103959665"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Jun 13 10:24:47 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P0    34W / 250W |    289MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# checking out the memory\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMz95ceql4qp",
        "outputId": "3b030be3-9f16-44a7-81b9-363714fbb5b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 27.3 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install hydroeval"
      ],
      "metadata": {
        "id": "7kyCtFRstXqI"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Running XGBoost model on Basel station"
      ],
      "metadata": {
        "id": "VhWM3ObX1I0Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "4KeOfoe_oc-3"
      },
      "outputs": [],
      "source": [
        "# required libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import hydroeval as he\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from xgboost.sklearn import XGBRegressor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zID4dw-3t2lm",
        "outputId": "4fcfb148-04f4-4c2c-bdfb-487d628ef829"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reading data \n",
        "basel = pd.read_csv('/content/drive/MyDrive/Thesis-Afshari/data/basel.csv',index_col=0)\n",
        "q_basel = pd.read_csv(\"/content/drive/MyDrive/Thesis-Afshari/data/q_basel.csv\",index_col=0)\n"
      ],
      "metadata": {
        "id": "_4g5OuacuHil"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# making lagged variables\n",
        "\n",
        "# define the number of lags\n",
        "TIME_STEPS = 60\n",
        "\n",
        "#add the lagged variables for predictors to the dataframe\n",
        "for i, var in enumerate(basel[[\"et\",\"p\",\"t\"]]):\n",
        "  for step in range(0, TIME_STEPS - 1):\n",
        "    basel.insert(i*(TIME_STEPS) + 1,\n",
        "                 f'{var}_lag_{TIME_STEPS - 1 - step}',\n",
        "                 basel[var].shift(TIME_STEPS - 1 - step))\n",
        "\n",
        "#remove the first TIME_STEPS - 1 rows since they will contain NA values\n",
        "basel = basel.iloc[TIME_STEPS - 1:,:].reset_index(drop=True)\n",
        "q_basel = q_basel.iloc[TIME_STEPS - 1:,:].reset_index(drop=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqY_pYwBu5YM",
        "outputId": "a26975e5-7ea3-4613-efbd-05a83fa9b56b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2822: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  if self.run_code(code, result):\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train_test split"
      ],
      "metadata": {
        "id": "T7oZ0J7fvFbQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train-test split\n",
        "len_ = int(0.75 * basel.shape[0])\n",
        "\n",
        "df_train = basel[:len_]\n",
        "df_test = basel[len_:]\n",
        "\n",
        "# x train without lagged vars\n",
        "X_train = df_train[[\"et\",\"t\",\"p\"]]\n",
        "\n",
        "# x train with lagged vars\n",
        "X_train_lagged = df_train.drop(columns = [\"obs\",\"datetime\"], axis =1)\n",
        "y_train = df_train.obs\n",
        "\n",
        "# x test without lagged vars\n",
        "X_test = df_test[[\"et\",\"t\",\"p\"]]\n",
        "\n",
        "# x test with lagged vars\n",
        "X_test_lagged = df_test.drop(columns = [\"obs\",\"datetime\"], axis =1)\n",
        "y_test = df_test.obs\n"
      ],
      "metadata": {
        "id": "yNTnfzk5vA3d"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hyperparameter grid search"
      ],
      "metadata": {
        "id": "EVC7VRJbvUso"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Various hyper-parameters to tune foe XGBoost model without input lagged variables \n",
        "\n",
        "xgb = XGBRegressor()\n",
        "parameters = {'nthread':[1], \n",
        "              'objective':['reg:squarederror'],\n",
        "              'learning_rate': [.01, .05, .1], \n",
        "              'max_depth': [7, 9], \n",
        "              'min_child_weight': [4],\n",
        "              'subsample': [0.8, 0.9], \n",
        "              'colsample_bytree': [0.7, 0.9], \n",
        "              'n_estimators': [800, 1000]} \n",
        "\n",
        "xgb_grid = GridSearchCV(xgb,\n",
        "                        parameters,\n",
        "                        cv = 5,\n",
        "                        n_jobs = 5,\n",
        "                        verbose=True)\n",
        "\n",
        "\n",
        "xgb_grid.fit(X_train,\n",
        "         y_train)\n",
        "\n",
        "print(f\"best score for XGBoost model without lagged variables is : {xgb_grid.best_score_}\")\n",
        "print(f\"best parameters XGBoost model without lagged variables are: {xgb_grid.best_params_}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27LzAv4ZvSkQ",
        "outputId": "325ff865-f987-4048-e247-bce1edbe393e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
            "best score for XGBoost model without lagged variables is : 0.04899852875704589\n",
            "best parameters XGBoost model without lagged variables are: {'colsample_bytree': 0.7, 'learning_rate': 0.01, 'max_depth': 7, 'min_child_weight': 4, 'n_estimators': 800, 'nthread': 1, 'objective': 'reg:squarederror', 'subsample': 0.9}\n",
            "CPU times: user 4.1 s, sys: 180 ms, total: 4.28 s\n",
            "Wall time: 4min 13s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Various hyper-parameters to tune foe XGBoost model with 60 input lagged variables \n",
        "\n",
        "xgb = XGBRegressor()\n",
        "parameters = {'nthread':[1], \n",
        "              'objective':['reg:squarederror'], \n",
        "              'learning_rate': [.01, .05, .1], \n",
        "              'max_depth': [7, 9], \n",
        "              'min_child_weight': [4],\n",
        "              'subsample': [0.8, 0.9], \n",
        "              'colsample_bytree': [0.7, 0.9], \n",
        "              'n_estimators': [800, 1000]} \n",
        "\n",
        "xgb_grid_lagged = GridSearchCV(xgb,\n",
        "                        parameters,\n",
        "                        cv = 5,\n",
        "                        n_jobs = 5,\n",
        "                        verbose=True)\n",
        "\n",
        "\n",
        "xgb_grid_lagged.fit(X_train_lagged,\n",
        "         y_train)\n",
        "\n",
        "print(f\"best score for XGBoost model with 60 lagged variables is : {xgb_grid.best_score_}\")\n",
        "print(f\"best parameters XGBoost model with 60 lagged variables are: {xgb_grid.best_params_}\")"
      ],
      "metadata": {
        "id": "-Ij3GHRWwn5o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d864a247-8d30-494a-9607-416976bd74a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
            "best score for XGBoost model with 60 lagged variables is : 0.04899852875704589\n",
            "best parameters XGBoost model with 60 lagged variables are: {'colsample_bytree': 0.7, 'learning_rate': 0.01, 'max_depth': 7, 'min_child_weight': 4, 'n_estimators': 800, 'nthread': 1, 'objective': 'reg:squarederror', 'subsample': 0.9}\n",
            "CPU times: user 1min 43s, sys: 4.44 s, total: 1min 47s\n",
            "Wall time: 1h 59min 46s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "uszGWHXVb7yF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define the model for without lagged variables model\n",
        "model =  xgb_grid.best_estimator_\n",
        "\n",
        "# fit model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# make a prediction\n",
        "yhat = model.predict(X_test)"
      ],
      "metadata": {
        "id": "zN4qNs_pb6KQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save model\n",
        "model.save_model('/content/drive/MyDrive/Thesis-Afshari/output/xgboost_lstm_without_lag.model')"
      ],
      "metadata": {
        "id": "kovsl0GPb6nP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the model for with 60 lagged variables model\n",
        "model_lagged =  xgb_grid_lagged.best_estimator_\n",
        "\n",
        "# fit model\n",
        "model_lagged.fit(X_train_lagged, y_train)\n",
        "# make a prediction\n",
        "yhat_lagged = model_lagged.predict(X_test_lagged)"
      ],
      "metadata": {
        "id": "P4MSJIWZco2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save model\n",
        "model_lagged.save_model('/content/drive/MyDrive/Thesis-Afshari/output/xgboost_lstm_with_60lag.model')\n",
        "\n",
        "# save prediction with lagged \n",
        "np.save(\"/content/drive/MyDrive/Thesis-Afshari/output/ypred_basel_xgboost_60lag.npy\", yhat_lagged, allow_pickle=True)\n"
      ],
      "metadata": {
        "id": "wONiSe-Qc8k3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "UfdLWIcGec4e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate pcr model using nse and kge\n",
        "streamflow_pcr = q_basel.pcr[len_:]\n",
        "nse_pcr = he.evaluator(he.nse, streamflow_pcr, y_test)\n",
        "kge_pcr, r, alpha, beta = he.evaluator(he.kge, streamflow_pcr, y_test)\n",
        "print(\"The nse and kge of the PCR model are {:.2} and {:.2}.\".format(nse_pcr[0], kge_pcr[0]))\n",
        "\n",
        "# evaluate the prediction using nse and kge for model with only meteorological variables\n",
        "nse = he.evaluator(he.nse, yhat, y_test)\n",
        "\n",
        "kge, r, alpha, beta = he.evaluator(he.kge, yhat, y_test)\n",
        "print(\"The nse and kge of the xgboost model are {:.2} and {:.2}.\".format(nse[0], kge[0]))\n",
        "\n",
        "# evaluate the prediction using nse and kge for model with meteorological variables + lagged variables\n",
        "nse_lag = he.evaluator(he.nse, yhat_lagged, y_test)\n",
        "kge_lag, r_lag, alpha_lag, beta_lag = he.evaluator(he.kge, yhat_lagged, y_test)\n",
        "\n",
        "print(\"The nse and kge of the xgboost model including lagged variables are {:.2} and {:.2}.\".format(nse_lag[0], kge_lag[0]))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZWwCxO8eYNM",
        "outputId": "df53d224-be2a-4478-8e89-72e778e41617"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The nse and kge of the PCR model are 0.22 and 0.64.\n",
            "The nse and kge of the xgboost model are 0.15 and 0.21.\n",
            "The nse and kge of the xgboost model including lagged variables are 0.61 and 0.6.\n"
          ]
        }
      ]
    }
  ]
}